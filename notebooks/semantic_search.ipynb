{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c12182ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai.embeddings_utils import get_embeddings, get_embedding\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0289c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ.get('OPENAI_API_KEY')\n",
    "pinecone_key = os.environ.get('PINECONE_API_KEY')\n",
    "\n",
    "INDEX_NAME = 'semantic-search'\n",
    "NAMESPACE = 'default'\n",
    "ENGINE = 'text-embedding-ada-002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544d9d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9befee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "pinecone.init(api_key=pinecone_key, environment=\"us-west1-gcp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea70672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not INDEX_NAME in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        INDEX_NAME,  # The name of the index\n",
    "        dimension=1536,  # The dimensionality of the vectors\n",
    "        metric='cosine',  # The similarity metric to use when searching the index\n",
    "        pod_type=\"p1\"  # The type of Pinecone pod\n",
    "    )\n",
    "\n",
    "# Store the index as a variable\n",
    "index = pinecone.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6103d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f2fdfe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4ed8caa969fba0d4b9500f0866996b76'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_hash(s):\n",
    "    # Return the MD5 hash of the input string as a hexadecimal string\n",
    "    return hashlib.md5(s.encode()).hexdigest()\n",
    "\n",
    "my_hash('I like to hash it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecd86f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_pinecone(texts, engine=ENGINE):\n",
    "    # Get the current UTC date and time\n",
    "    now = datetime.utcnow()\n",
    "    \n",
    "    # Generate vector embeddings for each string in the input list, using the specified engine\n",
    "    embeddings = get_embeddings(texts, engine=engine)\n",
    "    \n",
    "    # Create tuples of (hash, embedding, metadata) for each input string and its corresponding vector embedding\n",
    "    # The my_hash() function is used to generate a unique hash for each string, and the datetime.utcnow() function is used to generate the current UTC date and time\n",
    "    return [\n",
    "        (\n",
    "            my_hash(text),  # A unique ID for each string, generated using the my_hash() function\n",
    "            embedding,  # The vector embedding of the string\n",
    "            dict(text=text, date_uploaded=now)  # A dictionary of metadata, including the original text and the current UTC date and time\n",
    "        ) \n",
    "        for text, embedding in zip(texts, embeddings)  # Iterate over each input string and its corresponding vector embedding\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c40d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['hi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e1b73f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:   49f68a5c8493ec2c0bf489821c21fc3b \n",
      "LEN:  1536 \n",
      "META: {'text': 'hi', 'date_uploaded': datetime.datetime(2023, 8, 14, 14, 57, 11, 817858)}\n"
     ]
    }
   ],
   "source": [
    "_id, embedding, metadata = prepare_for_pinecone(texts)[0]\n",
    "\n",
    "print('ID:  ',_id, '\\nLEN: ', len(embedding), '\\nMETA:', metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49debd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf47aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_texts_to_pinecone(texts, namespace=NAMESPACE, batch_size=None, show_progress_bar=False):\n",
    "    # Call the prepare_for_pinecone function to prepare the input texts for indexing\n",
    "    total_upserted = 0\n",
    "    if not batch_size:\n",
    "        batch_size = len(texts)\n",
    "\n",
    "    _range = range(0, len(texts), batch_size)\n",
    "    for i in tqdm(_range) if show_progress_bar else _range:\n",
    "        batch = texts[i: i + batch_size]\n",
    "        prepared_texts = prepare_for_pinecone(batch)\n",
    "\n",
    "        # Use the upsert() method of the index object to upload the prepared texts to Pinecone\n",
    "        total_upserted += index.upsert(\n",
    "            prepared_texts,\n",
    "            namespace=namespace\n",
    "        )['upserted_count']\n",
    "\n",
    "    return total_upserted\n",
    "\n",
    "\n",
    "# Call the upload_texts_to_pinecone() function with the input texts\n",
    "upload_texts_to_pinecone(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8ed7e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '49f68a5c8493ec2c0bf489821c21fc3b',\n",
       "  'metadata': {'date_uploaded': datetime.datetime(2023, 8, 14, 14, 57, 43, 111756),\n",
       "               'text': 'hi'},\n",
       "  'score': 0.924787819,\n",
       "  'values': []}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query_from_pinecone(query, top_k=3):\n",
    "    # get embedding from THE SAME embedder as the documents\n",
    "    query_embedding = get_embedding(query, engine=ENGINE)\n",
    "\n",
    "    return index.query(\n",
    "      vector=query_embedding,\n",
    "      top_k=top_k,\n",
    "      namespace=NAMESPACE,\n",
    "      include_metadata=True   # gets the metadata (dates, text, etc)\n",
    "    ).get('matches')\n",
    "\n",
    "query_from_pinecone('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "622218d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '49f68a5c8493ec2c0bf489821c21fc3b',\n",
       "  'metadata': {'date_uploaded': datetime.datetime(2023, 8, 14, 14, 57, 43, 111756),\n",
       "               'text': 'hi'},\n",
       "  'score': 0.749424815,\n",
       "  'values': []}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_from_pinecone('What are fixed costs?')  # something will ALWAYS be returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84a0871f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "def delete_texts_from_pinecone(texts, namespace=NAMESPACE):\n",
    "    # Compute the hash (id) for each text\n",
    "    hashes = [hashlib.md5(text.encode()).hexdigest() for text in texts]\n",
    "    \n",
    "    # The ids parameter is used to specify the list of IDs (hashes) to delete\n",
    "    return index.delete(ids=hashes, namespace=namespace)\n",
    "\n",
    "# delete our text\n",
    "delete_texts_from_pinecone(texts)\n",
    "\n",
    "# test that the index is empty\n",
    "query_from_pinecone('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b195bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72729603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36661, 1070]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the tiktoken library\n",
    "import tiktoken\n",
    "\n",
    "# Initializing a tokenizer for the 'cl100k_base' model\n",
    "# This tokenizer is designed to work with the 'ada-002' embedding model\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# Using the tokenizer to encode the text 'hey there'\n",
    "# The resulting output is a list of integers representing the encoded text\n",
    "# This is the input format required for embedding using the 'ada-002' model\n",
    "tokenizer.encode('hey there')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc147d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62e28784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset boolq (/Users/sinanozdemir/.cache/huggingface/datasets/boolq/default/0.1.0/bf0dd57da941c50de94ae3ce3cef7fea48c08f337a4b7aac484e9dddc5aa24e5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8893154fad143e5bca612fe696fc7e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"boolq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6773457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'does ethanol take more energy make that produces',\n",
       " 'answer': False,\n",
       " 'passage': \"All biomass goes through at least some of these steps: it needs to be grown, collected, dried, fermented, distilled, and burned. All of these steps require resources and an infrastructure. The total amount of energy input into the process compared to the energy released by burning the resulting ethanol fuel is known as the energy balance (or ``energy returned on energy invested''). Figures compiled in a 2007 report by National Geographic Magazine point to modest results for corn ethanol produced in the US: one unit of fossil-fuel energy is required to create 1.3 energy units from the resulting ethanol. The energy balance for sugarcane ethanol produced in Brazil is more favorable, with one unit of fossil-fuel energy required to create 8 from the ethanol. Energy balance estimates are not easily produced, thus numerous such reports have been generated that are contradictory. For instance, a separate survey reports that production of ethanol from sugarcane, which requires a tropical climate to grow productively, returns from 8 to 9 units of energy for each unit expended, as compared to corn, which only returns about 1.34 units of fuel energy for each unit of energy expended. A 2006 University of California Berkeley study, after analyzing six separate studies, concluded that producing ethanol from corn uses much less petroleum than producing gasoline.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['validation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0221343a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 13/13 [06:29<00:00, 29.99s/it]\n"
     ]
    }
   ],
   "source": [
    "for idx in tqdm(range(0, len(dataset['validation']), 256)):\n",
    "    data_sample = dataset['validation'][idx:idx + 256]\n",
    "\n",
    "    passages = data_sample['passage']\n",
    "\n",
    "    upload_texts_to_pinecone(passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "414fc2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_pinecone(query, top_k=3, verbose=True):\n",
    "\n",
    "    results_from_pinecone = query_from_pinecone(query, top_k=top_k)\n",
    "    if not results_from_pinecone:\n",
    "        return []\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Query:\", query)\n",
    "    \n",
    "    \n",
    "    final_results = []\n",
    "\n",
    "    if verbose:\n",
    "        print('Document ID (Hash)\\t\\tRetrieval Score\\tText')\n",
    "    for result_from_pinecone in results_from_pinecone:\n",
    "        final_results.append(result_from_pinecone)\n",
    "        if verbose:\n",
    "            print(f\"{result_from_pinecone['id']}\\t{result_from_pinecone['score']:.2f}\\t{result_from_pinecone['metadata']['text'][:50]}\")\n",
    "\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9802a9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c20f66e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is it possible to thunder and lightning while snowing\n",
      "Query: is it possible to thunder and lightning while snowing\n",
      "Document ID (Hash)\t\tRetrieval Score\tText\n",
      "cfa9150bac58fea67fec83e20d7ac29f\t0.85\tThundersnow, also known as a winter thunderstorm o\n",
      "e64ea582a771606ccfcde248c189a0a6\t0.81\tOn somewhat rare occasions, a thunderstorm can bec\n",
      "9b2a2c201b62136f19d6f4e8409cef14\t0.81\tA dry thunderstorm or heat storm is a thunderstorm\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "\n",
    "query = sample(dataset['validation']['question'], 1)[0]\n",
    "print(query)\n",
    "final_results = get_results_from_pinecone(query, top_k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1e27222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cfa9150bac58fea67fec83e20d7ac29f'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_to_hash = {data['question']: my_hash(data['passage']) for data in dataset['validation']}\n",
    "\n",
    "q_to_hash[query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dd15f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe4a6c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3270/3270 [26:09<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with OpenAI embeddings: 0.8532110091743119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# Note we will keep top_k the same so latency from Pinecone is consistent\n",
    "#  and the only major time difference will be in the re-ranking\n",
    "\n",
    "for question in tqdm(dataset['validation']['question']):\n",
    "    retrieved_hash = get_results_from_pinecone(question, top_k=1, verbose=False)[0]['id']\n",
    "    correct_hash = q_to_hash[question]\n",
    "    predictions.append(retrieved_hash == correct_hash)\n",
    "    \n",
    "accuracy = sum(predictions)/len(predictions)\n",
    "\n",
    "print(f'Accuracy with OpenAI embeddings: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f14809e",
   "metadata": {},
   "source": [
    "# OPEN SOURCE ALTERNATIVE TO EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99138055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221b9431ada84ad6bf43eff48ed88242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-cos-v1')\n",
    "\n",
    "docs = [\"Around 9 Million people live in London\", \"London is known for its financial district\"]\n",
    "\n",
    "doc_emb = model.encode(docs, batch_size=32, show_progress_bar=True)\n",
    "\n",
    "doc_emb.shape#  == ('2, 768')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1140c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be37c48b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777d5ff52d1d4aa494c02d3a0f3edec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Encode query and documents\n",
    "docs = dataset['validation']['passage']\n",
    "doc_emb = model.encode(docs, batch_size=32, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae0afee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can you really hear the ocean in a seashell\n",
      "Query: can you really hear the ocean in a seashell\n",
      "Document ID (Hash)\t\tRetrieval Score\tText\n",
      "0612760f30f0cb57c712eeea99a3b0e9\t0.84\tThe rushing sound that one hears is in fact the no\n",
      "a0b84b6b6637a89fdde0cfb285371469\t0.76\tMarlin and Nemo attempt to rescue Dory. With the h\n",
      "8691b3d6b92277de6cb7bd9cff973c00\t0.76\tThe most common marine fish in the Sound include p\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "\n",
    "query = sample(dataset['validation']['question'], 1)[0]\n",
    "print(query)\n",
    "# Using OpenAI\n",
    "final_results = get_results_from_pinecone(query, top_k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d871572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45c71fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7952df2368044c8eac8e0ca985bb57a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6290125846862793 The rushing sound that one hears is in fact the noise of the surrounding environment, resonating within the cavity of the shell. The same effect can be produced with any resonant cavity, such as an empty cup or even by simply cupping one's hand over one's ear. The similarity of the noise produced by the resonator to that of the oceans is due to the resemblance between ocean movements and airflow.\n",
      "0.4079173803329468 The most common marine fish in the Sound include porgy, butterfish, winter flounder, summer flounder, windowpane flounder, fourspot flounder, northern and striped sea robin, little skate, menhaden, Atlantic silversides, black seabass, blackfish (tautog), cunner, bluefish, and smooth dogfish. Frequently Atlantic bonito and false albacore, both members of the tuna family, enter the sound and can be caught by anglers from small boats and shore. Many species have declined rapidly since 1975 due to over fishing. Winter flounder may not be currently present except for rare, small local populations. Tautog and summer flounder are also less numerous. Anadromous fishes include striped bass, white perch, alewives, blueback herring, and American and hickory shad. Although several shark species likely infrequently wander in and out of the Sound, e.g. blue shark, mako shark, hammerhead shark & thresher shark, there are only four species of sharks which are regularly found in the area. These are the sand tiger shark, the sandbar shark, the spiny dogfish and the smooth dogfish.\n",
      "0.39156773686408997 In common everyday speech, speed of sound refers to the speed of sound waves in air. However, the speed of sound varies from substance to substance: sound travels most slowly in gases; it travels faster in liquids; and faster still in solids. For example, (as noted above), sound travels at 343 m/s in air; it travels at 1,484 m/s in water (4.3 times as fast as in air); and at 5,120 m/s in iron (about 15 times as fast as in air). In an exceptionally stiff material such as diamond, sound travels at 12,000 metres per second (26,843 mph); (about 35 times as fast as in air) which is around the maximum speed that sound will travel under normal conditions.\n"
     ]
    }
   ],
   "source": [
    "query_emb = model.encode(query)\n",
    "\n",
    "#Compute dot score between query and all document embeddings\n",
    "scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()\n",
    "\n",
    "#Combine docs & scores\n",
    "doc_score_pairs = list(zip(docs, scores))\n",
    "\n",
    "#Sort by decreasing score\n",
    "doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#Output passages & scores\n",
    "for doc, score in doc_score_pairs[:3]:\n",
    "    print(score, doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8533d9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93280be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "logger.setLevel(logging.CRITICAL)  # just to suppress some logs\n",
    "\n",
    "\n",
    "def eval_ranking_open_source(query, top_k=3):\n",
    "    query_emb = np.array(model.encode(query))\n",
    "\n",
    "    #Compute dot score between query and all document embeddings\n",
    "    scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()\n",
    "\n",
    "    #Combine docs & scores\n",
    "    doc_score_pairs = list(zip(docs, scores))\n",
    "\n",
    "    #Sort by decreasing score\n",
    "    doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "    retrieved_hash = my_hash(doc_score_pairs[0][0])\n",
    "    return retrieved_hash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06f198cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0612760f30f0cb57c712eeea99a3b0e9'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ranking_open_source(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffd68ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▏                                   | 103/814 [00:05<00:38, 18.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100\n",
      "Accuracy: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████▏                              | 202/814 [00:10<00:31, 19.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200\n",
      "Accuracy: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████▏                         | 302/814 [00:16<00:26, 19.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300\n",
      "Accuracy: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████▎                    | 403/814 [00:21<00:20, 19.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400\n",
      "Accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████▎               | 503/814 [00:26<00:16, 18.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500\n",
      "Accuracy: 0.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|██████████████████████████████▎          | 603/814 [00:31<00:10, 19.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600\n",
      "Accuracy: 0.8133333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████▎     | 702/814 [00:36<00:05, 18.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 700\n",
      "Accuracy: 0.8228571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████▍| 802/814 [00:42<00:00, 17.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 800\n",
      "Accuracy: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 814/814 [00:42<00:00, 19.02it/s]\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "i = 0\n",
    "print_every = 100\n",
    "predictions = []\n",
    "for question in tqdm(dataset['validation']['question']):\n",
    "    retrieved_hash = eval_ranking_open_source(question, top_k=3)\n",
    "    correct_hash = q_to_hash[question]\n",
    "    predictions.append(retrieved_hash == correct_hash)\n",
    "    i += 1\n",
    "    if i % print_every == 0:\n",
    "        print(f'Step {i}')\n",
    "        raw_accuracy = sum(predictions)/len(predictions)\n",
    "\n",
    "        print(f'Accuracy: {raw_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b95b371a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with open source embedder: 0.8206388206388207\n"
     ]
    }
   ],
   "source": [
    "raw_accuracy = sum(predictions)/len(predictions)\n",
    "print(f'Accuracy with open source embedder: {raw_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95735104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
